# Building-RAG-from-Scratch

ğŸš€ Built a Retrieval-Augmented Generation (RAG) System from Scratch!
I recently completed a hands-on project where I built a RAG system entirely from the ground up â€” using tools that real engineers use to build scalable, production-level AI systems.
Hereâ€™s a quick breakdown of the tools I used and what I learned ğŸ‘‡
ğŸ§  1. Transformers (Hugging Face)
 Used for the generation part of RAG â€” this provides access to powerful open-source LLMs that take the retrieved context and generate accurate, human-like responses. Itâ€™s the â€œbrainâ€ that crafts the final output.
ğŸ” 2. Sentence-Transformers
 Responsible for converting text into dense vector embeddings â€” numerical representations that capture the meaning of text. This helps the system understand semantic similarity between a question and the stored documents.
âš¡ 3. FAISS (Facebook AI Similarity Search)
 A vector search engine built by Meta AI, designed for lightning-fast similarity search across large datasets. It stores embeddings and retrieves the most relevant chunks of information in real-time.
ğŸ§© 4. LangChain
 I used LangChainâ€™s Text Splitter to automatically divide documents into smaller, context-friendly chunks â€” saving hours of manual preprocessing. This ensures that each chunk fits within the modelâ€™s token limits.
ğŸ§  How it all connects:
Split text â†’ Embed â†’ Index â†’ Retrieve â†’ Generate!
 LangChain splits â†’ Sentence-Transformers embeds â†’ FAISS retrieves â†’ Transformers generate the final response.
ğŸ’¡ Key Takeaway:
 Building RAG from scratch gave me a deep understanding of how modern AI systems combine retrieval and generation to produce accurate, context-aware answers.
